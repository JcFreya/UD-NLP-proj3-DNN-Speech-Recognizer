
# DNN Speech Recognizer

## Introduction
In this notebook, we will build a deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline.

## Overview
- Investigating the [LibriSpeech dataset](http://www.openslr.org/12/) that will be used to train and evaluate models.
- Convert any raw audio to feature representations that are commonly used for ASR.
- Building neural networks that can map these audio features to transcribed text with appropriate types of layers that are often used for deep learning-based approaches to ASR

# Steps

The tasks for this project are outlined in the  `vui_notebook.ipynb`  in three steps. Follow all the instructions, which include implementing code in  `sample_models.py`. The following list is a summary of the tasks.

![](https://video.udacity-data.com/topher/2017/June/594fea46_pipeline/pipeline.png)

## Step 1 - Feature Extraction

-   Execute all code cells to extract features from raw audio

## Step 2 - Acoustic Model

-   Implement the code for Models 1, 2, 3, and 4 in  `sample_models.py`
-   Train Models 0, 1, 2, 3, 4 in the notebook
-   Execute the comparison code in the notebook
-   Answer Question 1 in the notebook regarding the comparison
-   Implement the code for the Final Model in  `sample_models.py`
-   Train the Final Model in the notebook
-   Answer Question 2 in the notebook regarding your final model

## Step 3 - Decoder

-   Execute the prediction code in the notebook
